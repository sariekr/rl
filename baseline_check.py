import torch
import json
import re
from transformers import AutoTokenizer, AutoModelForCausalLM

# 1. AYARLAR
base_model_id = "OpenPipe/Qwen3-14B-Instruct"

# 2. TEST VERÄ°SÄ°NÄ° YÃœKLE
try:
    with open("dataset_test.json", "r") as f: dataset = json.load(f)
    print(f"âœ… Test Verisi YÃ¼klendi: {len(dataset)} adet (Model bunlarÄ± hiÃ§ gÃ¶rmedi)")
except:
    print("âŒ Dataset yok! 'generate_balanced_dataset.py' Ã§alÄ±ÅŸtÄ±r.")
    exit()

# 3. BASELINE MODELÄ° YÃœKLE (AdaptÃ¶rsÃ¼z, Saf Hali)
print(f"ğŸ“‰ Baseline Model YÃ¼kleniyor: {base_model_id}...")
tokenizer = AutoTokenizer.from_pretrained(base_model_id, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    base_model_id,
    torch_dtype=torch.bfloat16,
    device_map="auto",
    trust_remote_code=True
)

# 4. KÃ–R SYSTEM PROMPT
system_prompt = """You are a credit risk engine for FinCorp. 
Output JSON: {"decision": "..."}
Allowed Decisions: [A_PLUS_TIER, REJECT_RISK, MANUAL_REVIEW, STANDARD_LOAN]."""

# 5. TEST DÃ–NGÃœSÃœ
correct = 0
total = 0
stats = {k: {"correct": 0, "total": 0} for k in ["A_PLUS_TIER", "REJECT_RISK", "MANUAL_REVIEW", "STANDARD_LOAN"]}

print(f"\n{'BAÅVURU (Ã–zet)':<40} | {'BEKLENEN':<15} | {'BASELINE':<15} | {'DURUM'}")
print("-" * 85)

for item in dataset: # TÃ¼m test setini (160 adet) dÃ¶nÃ¼yoruz
    prompt = item['prompt']
    expected_json = json.loads(item['ground_truth'])
    expected = expected_json['decision']
    
    # Prompt Ã–zeti
    founder = "Ex-Tech" if "Ex-" in prompt else "Norm"
    rev_match = re.search(r'Revenue: \$([\d,]+)', prompt)
    rev = rev_match.group(1)[:3] + "k" if rev_match else "?"
    summary = f"F:{founder} | Rev:${rev}"

    # Modelden Cevap Al
    text = tokenizer.apply_chat_template([
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": prompt}
    ], tokenize=False, add_generation_prompt=True)
    
    inputs = tokenizer([text], return_tensors="pt").to("cuda")
    with torch.no_grad():
        out = model.generate(**inputs, max_new_tokens=50, temperature=0.1)
    
    resp = tokenizer.batch_decode(out[:, inputs.input_ids.shape[1]:], skip_special_tokens=True)[0]
    
    # CevabÄ± AyÄ±kla
    decision = "INVALID"
    try:
        if "{" in resp: 
            decision = json.loads(resp[resp.find('{'):resp.rfind('}')+1]).get('decision', 'INVALID')
        else:
            for k in stats.keys():
                if k in resp: decision = k; break
    except: pass
    
    # Ä°statistikleri GÃ¼ncelle
    total += 1
    stats[expected]["total"] += 1
    
    is_correct = (decision == expected)
    if is_correct: 
        correct += 1
        stats[expected]["correct"] += 1
    
    # Sadece ilk 10 ve hatalÄ± olanlarÄ± yazdÄ±ralÄ±m ki ekran dolmasÄ±n
    if total <= 10 or not is_correct:
        icon = "âœ…" if is_correct else "âŒ"
        print(f"{summary:<40} | {expected:<15} | {decision:<15} | {icon}")

print("-" * 85)
print(f"ğŸ“‰ BASELINE GENEL SKOR: %{correct/total*100:.1f} ({correct}/{total})")
print("\n--- DETAYLI KIRILIM ---")
for k, v in stats.items():
    acc = (v['correct']/v['total']*100) if v['total'] > 0 else 0
    print(f"{k:<15}: %{acc:.1f} ({v['correct']}/{v['total']})")
print("=" * 85)